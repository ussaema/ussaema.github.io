<table class="responsive" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
  <tr>  
<td width="40%">
    <div class="one">
    <img src="/images/projects/seqcapsgan.png" width="100%" class="img"/>
</div>
  </td>
    <td valign="top" width="75%">
      <papertitle>
        <strong>
          <a href="https://github.com/ussaema/SeqCapsGAN" target="_blank">
            SeqCapsGAN: Generating Image Stylized Captioning using Capsule GANs
          </a>
        </strong>
      </papertitle>
      <em>Course: Natural Language Processing</em>
<br>
    <em>2020</em>
      <br>
      <a href="https://github.com/ussaema/SeqCapsGAN" target="_blank">Github Repo</a> | 
      <a href="https://github.com/ussaema/SeqCapsGAN/blob/master/Paper.pdf" target="_blank">Report</a>
      <br>
We introduce SeqCapsGAN, a stylized image captioning framework that combines Generative Adversarial Networks and Capsule Networks to generate human-like captions with sentiment, outperforming baseline models on key evaluation metrics.
</td>
  </tr>
</table>


<table class="responsive" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
  <tr>  
<td width="40%">
    <div class="one">
    <img src="/images/projects/emg_gan.png" width="100%" class="img"/>
</div>
  </td>
    <td valign="top" width="75%">
      <papertitle>
        <strong>
          <a href="https://github.com/ussaema/EMGCaps" target="_blank">
            EMGCaps: Electromyographic Hand Gesture Recognition using Capsule Network
          </a>
        </strong>
      </papertitle>
      <em>Practical course at NTU</em>
<br>
    <em>2020</em>
      <br>
      <a href="https://github.com/ussaema/EMGCaps" target="_blank">Github Repo</a> | 
      <a href="https://github.com/ussaema/EMGCaps/blob/master/Paper.pdf" target="_blank">Report</a>
      <br>
We introduce EMG-Caps, a framework for hand gesture classification using Capsule Networks on sEMG signals from the NinaPro DB5 dataset, demonstrating that CapsNets outperform conventional classifiers and other deep learning methods—achieving up to 93.27% accuracy across 53 hand movements.
</td>
  </tr>
</table>

<table class="responsive" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
  <tr>  
<td width="40%">
    <div class="one">
    <img src="/images/projects/robot_arm_control.png" width="100%" class="img"/>
</div>
  </td>
    <td valign="top" width="75%">
      <papertitle>
        <strong>
          <a href="https://github.com/ussaema/Trajectory_Planning_using_Bi-RRT_Algorithm" target="_blank">
            Electromyography-based Control of a Simulated Robot Arm
          </a>
        </strong>
      </papertitle>
      <em>Practical course Networked and Cooperative Systems by <a href="https://www.ce.cit.tum.de/itr/hirche/" target="_blank">Prof. Sandra Hirche</a></em>
<br>
    <em>2019</em>
      <br>
      <a href="https://github.com/ussaema/Trajectory_Planning_using_Bi-RRT_Algorithm" target="_blank">Github Repo</a> |
      <a href="https://github.com/ussaema/Trajectory_Planning_using_Bi-RRT_Algorithm/blob/main/Paper.pdf" target="_blank">Report</a>
      <br>
We performed data acquisition and preprocessing, designed and evaluated classification systems using both conventional and neural network–based pattern recognition methods in TensorFlow and Keras, and implemented a real-time operating 6-DoF robot arm.
</td>
  </tr>
</table>

<table class="responsive" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
  <tr>  
<td width="40%">
    <div class="one">
    <img src="/images/projects/robocup.png" width="100%" class="img"/>
</div>
  </td>
    <td valign="top" width="75%">
      <papertitle>
        <strong>
          <a href="https://github.com/ussaema/Trajectory_Planning_using_Bi-RRT_Algorithm" target="_blank">
            Trajectory Planning for Humanoid RoboCup using bi-RTT Algorithm
          </a>
        </strong>
      </papertitle>
      <em>Practical course Advanced Lab Humanoid RoboCup by <a href="https://www.ce.cit.tum.de/ics/people/cheng/" target="_blank">Prof. Gordon Cheng</a></em>
<br>
    <em>2019</em>
      <br>
      <a href="https://github.com/ussaema/Trajectory_Planning_using_Bi-RRT_Algorithm" target="_blank">Github Repo</a>
      <br>
We implemented trajectory planning algorithms (RRT/RRT*) in C++, simulated and evaluated their performance in both simple and challenging scenarios, and conducted real-world testing on the NAO robot using ROS.
</td>
  </tr>
</table>


<table class="responsive" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
  <tr>  
<td width="40%">
    <div class="one">
    <img src="/images/projects/oar.png" width="100%" class="img"/>
</div>
  </td>
    <td valign="top" width="75%">
      <papertitle>
        <strong>
          <a href="https://github.com/ussaema/Hand_Gesture_Controlled_Obstacle_Avoiding_Robot" target="_blank">
            Hand Gesture Controlled Obstacle Avoiding Robot
          </a>
        </strong>
      </papertitle>
      <em>Project of the course Humanoid Sensors and Actuators by <a href="https://www.ce.cit.tum.de/ics/people/cheng/" target="_blank">Prof. Gordon Cheng</a></em>
<br>
    <em>2019</em>
      <br>
      <a href="https://github.com/ussaema/Hand_Gesture_Controlled_Obstacle_Avoiding_Robot" target="_blank">Github Repo</a>
      <br>
We developed Hand Gesture Controlled Obstacle Avoiding Robot, implementing embedded programming in C++ on an Atmega328P microcontroller, sensor signal processing with a 6DoF IMU, ultrasonic and IR sensors, actuation control for servos, gear motors, and vibration motors, and a custom communication protocol for a radio transmitter/receiver module.
</td>
  </tr>
</table>

<table class="responsive" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
  <tr>  
<td width="40%">
    <div class="one">
    <img src="/images/projects/box_office.png" width="100%" class="img"/>
</div>
  </td>
    <td valign="top" width="75%">
      <papertitle>
        <strong>
          <a href="https://github.com/ussaema/Box_Office_Sales_Estimation" target="_blank">
            Prediction Opening-Weekend Box Office Sales based on Movie Trailers
          </a>
        </strong>
      </papertitle>
      <em>Project of the course Applied Machine Learning by <a href="https://www.professoren.tum.de/diepold-klaus" target="_blank">Prof. Klaus Diepold</a></em>
<br>
    <em>2019</em>
    <br>
      <br>
      <a href="https://github.com/ussaema/Box_Office_Sales_Estimation" target="_blank">Github Repo</a>
      <br>
In this project, we presented a system for predicting opening weekend box office sales from movie trailers by combining metadata (e.g., actors, studio, genre) with audio-visual features (e.g., spectrograms, colors, emotions), and implemented a frontend that enables users to run predictions on arbitrary YouTube trailers.
</td>
  </tr>
</table>


<table class="responsive" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
  <tr>  
<td width="40%">
    <div class="one">
    <img src="/images/projects/capsgan.png" width="100%" class="img"/>
</div>
  </td>
    <td valign="top" width="75%">
      <papertitle>
        <strong>
          <a href="https://github.com/ussaema/Vector_Matrix_CapsuleGAN" target="_blank">
            Generative Modelling using Capsule Generative Adversarial Networks
          </a>
        </strong>
      </papertitle>
      <em>Bachelor Thesis supervised by <a href="https://www.linkedin.com/in/alexander-kuhn-4a680714b/" target="_blank">Alexander Kuhn</a>, <a href="https://www.ce.cit.tum.de/en/air/people/prof-dr-ing-habil-alois-knoll/" target="_blank">Prof. Alois Knoll</a>, and <a href="https://www.professoren.tum.de/diepold-klaus" target="_blank">Prof. Klaus Diepold</a></em>
      <br>
    <em>2018</em>
    <br>
      <a href="https://github.com/ussaema/Vector_Matrix_CapsuleGAN" target="_blank">Github Repo</a>
      <br>
This thesis introduces CapsGAN, a generative modeling framework that integrates capsule networks into the GAN discriminator to better preserve spatial relationships, evaluates different CapsGAN architectures and routing algorithms, and demonstrates that dynamic routing improves training stability and sample quality compared to standard GAN approaches.
</td>
  </tr>
</table>


<table class="responsive" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
  <tr>  
<td width="40%">
    <div class="one">
    <img src="/images/projects/ct.png" width="100%" class="img"/>
</div>
  </td>
    <td valign="top" width="75%">
      <papertitle>
        <strong>
          <a href="https://github.com/ussaema/CT_Image_Reconstruction" target="_blank">
            Computed Tomography Image Reconstruction
          </a>
        </strong>
      </papertitle>
      <em>Project in the scope of Ferienakademie by TUM, University of Erlangen and University of Stuttgart</em>
    <br>
    <em>2018</em>
      <br>
      <a href="https://github.com/ussaema/CT_Image_Reconstruction" target="_blank">Github Repo</a>
      <br>
In this project, we develop a deep learning–based learnable filter to enhance the CT image reconstruction pipeline for improved image quality and reconstruction accuracy.
</td>
  </tr>
</table>